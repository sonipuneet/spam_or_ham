{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3a2b0e8cae14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# Author - Puneet Soni (Software Engineer) \n",
    "# Year - 2019\n",
    "# Project for Learning Purpose\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
    "mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails.rename(columns = {'v1': 'labels', 'v2': 'message'}, inplace = True)\n",
    "mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails['label'] = mails['labels'].map({'ham': 0, 'spam': 1})\n",
    "mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails.drop(['labels'], axis = 1, inplace = True)\n",
    "mails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalMails = 4825 + 747\n",
    "trainIndex, testIndex = list(), list()\n",
    "for i in range(mails.shape[0]):\n",
    "    if np.random.uniform(0, 1) < 0.75:\n",
    "        trainIndex += [i]\n",
    "    else:\n",
    "        testIndex += [i]\n",
    "trainData = mails.loc[trainIndex]\n",
    "testData = mails.loc[testIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.reset_index(inplace = True)\n",
    "trainData.drop(['index'], axis = 1, inplace = True)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.reset_index(inplace = True)\n",
    "testData.drop(['index'], axis = 1, inplace = True)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words = ' '.join(list(mails[mails['label'] == 1]['message']))\n",
    "spam_wc = WordCloud(width = 512,height = 512).generate(spam_words)\n",
    "plt.figure(figsize = (10, 8), facecolor = 'k')\n",
    "plt.imshow(spam_wc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_words = ' '.join(list(mails[mails['label'] == 0]['message']))\n",
    "ham_wc = WordCloud(width = 512,height = 512).generate(ham_words)\n",
    "plt.figure(figsize = (10, 8), facecolor = 'k')\n",
    "plt.imshow(ham_wc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    if gram > 1:\n",
    "        w = []\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            w += [' '.join(words[i:i + gram])]\n",
    "        return w\n",
    "    if stop_words:\n",
    "        sw = stopwords.words('english')\n",
    "        words = [word for word in words if word not in sw]\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]   \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier(object):\n",
    "    def __init__(self, trainData, method = 'tf-idf'):\n",
    "        self.mails, self.labels = trainData['message'], trainData['label']\n",
    "        self.method = method\n",
    "\n",
    "    def train(self):\n",
    "        self.calc_TF_and_IDF()\n",
    "        if self.method == 'tf-idf':\n",
    "            self.calc_TF_IDF()\n",
    "        else:\n",
    "            self.calc_prob()\n",
    "\n",
    "    def calc_prob(self):\n",
    "        self.prob_spam = dict()\n",
    "        self.prob_ham = dict()\n",
    "        for word in self.tf_spam:\n",
    "            self.prob_spam[word] = (self.tf_spam[word] + 1) / (self.spam_words + \\\n",
    "                                                                len(list(self.tf_spam.keys())))\n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.tf_ham[word] + 1) / (self.ham_words + \\\n",
    "                                                                len(list(self.tf_ham.keys())))\n",
    "        self.prob_spam_mail, self.prob_ham_mail = self.spam_mails / self.total_mails, self.ham_mails / self.total_mails \n",
    "\n",
    "\n",
    "    def calc_TF_and_IDF(self):\n",
    "        noOfMessages = self.mails.shape[0]\n",
    "        self.spam_mails, self.ham_mails = self.labels.value_counts()[1], self.labels.value_counts()[0]\n",
    "        self.total_mails = self.spam_mails + self.ham_mails\n",
    "        self.spam_words = 0\n",
    "        self.ham_words = 0\n",
    "        self.tf_spam = dict()\n",
    "        self.tf_ham = dict()\n",
    "        self.idf_spam = dict()\n",
    "        self.idf_ham = dict()\n",
    "        for i in range(noOfMessages):\n",
    "            message_processed = process_message(self.mails[i])\n",
    "            count = list() #To keep track of whether the word has ocured in the message or not.\n",
    "                           #For IDF\n",
    "            for word in message_processed:\n",
    "                if self.labels[i]:\n",
    "                    self.tf_spam[word] = self.tf_spam.get(word, 0) + 1\n",
    "                    self.spam_words += 1\n",
    "                else:\n",
    "                    self.tf_ham[word] = self.tf_ham.get(word, 0) + 1\n",
    "                    self.ham_words += 1\n",
    "                if word not in count:\n",
    "                    count += [word]\n",
    "            for word in count:\n",
    "                if self.labels[i]:\n",
    "                    self.idf_spam[word] = self.idf_spam.get(word, 0) + 1\n",
    "                else:\n",
    "                    self.idf_ham[word] = self.idf_ham.get(word, 0) + 1\n",
    "\n",
    "    def calc_TF_IDF(self):\n",
    "        self.prob_spam = dict()\n",
    "        self.prob_ham = dict()\n",
    "        self.sum_tf_idf_spam = 0\n",
    "        self.sum_tf_idf_ham = 0\n",
    "        for word in self.tf_spam:\n",
    "            self.prob_spam[word] = (self.tf_spam[word]) * log((self.spam_mails + self.ham_mails) \\\n",
    "                                                          / (self.idf_spam[word] + self.idf_ham.get(word, 0)))\n",
    "            self.sum_tf_idf_spam += self.prob_spam[word]\n",
    "        for word in self.tf_spam:\n",
    "            self.prob_spam[word] = (self.prob_spam[word] + 1) / (self.sum_tf_idf_spam + len(list(self.prob_spam.keys())))\n",
    "            \n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.tf_ham[word]) * log((self.spam_mails + self.ham_mails) \\\n",
    "                                                          / (self.idf_spam.get(word, 0) + self.idf_ham[word]))\n",
    "            self.sum_tf_idf_ham += self.prob_ham[word]\n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.prob_ham[word] + 1) / (self.sum_tf_idf_ham + len(list(self.prob_ham.keys())))\n",
    "            \n",
    "    \n",
    "        self.prob_spam_mail, self.prob_ham_mail = self.spam_mails / self.total_mails, self.ham_mails / self.total_mails \n",
    "                    \n",
    "    def classify(self, processed_message):\n",
    "        pSpam, pHam = 0, 0\n",
    "        for word in processed_message:                \n",
    "            if word in self.prob_spam:\n",
    "                pSpam += log(self.prob_spam[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pSpam -= log(self.sum_tf_idf_spam + len(list(self.prob_spam.keys())))\n",
    "                else:\n",
    "                    pSpam -= log(self.spam_words + len(list(self.prob_spam.keys())))\n",
    "            if word in self.prob_ham:\n",
    "                pHam += log(self.prob_ham[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pHam -= log(self.sum_tf_idf_ham + len(list(self.prob_ham.keys()))) \n",
    "                else:\n",
    "                    pHam -= log(self.ham_words + len(list(self.prob_ham.keys())))\n",
    "            pSpam += log(self.prob_spam_mail)\n",
    "            pHam += log(self.prob_ham_mail)\n",
    "        return pSpam >= pHam\n",
    "    \n",
    "    def predict(self, testData):\n",
    "        result = dict()\n",
    "        for (i, message) in enumerate(testData):\n",
    "            processed_message = process_message(message)\n",
    "            result[i] = int(self.classify(processed_message))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(labels, predictions):\n",
    "    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n",
    "    for i in range(len(labels)):\n",
    "        true_pos += int(labels[i] == 1 and predictions[i] == 1)\n",
    "        true_neg += int(labels[i] == 0 and predictions[i] == 0)\n",
    "        false_pos += int(labels[i] == 0 and predictions[i] == 1)\n",
    "        false_neg += int(labels[i] == 1 and predictions[i] == 0)\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    Fscore = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F-score: \", Fscore)\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_tf_idf = SpamClassifier(trainData, 'tf-idf')\n",
    "sc_tf_idf.train()\n",
    "preds_tf_idf = sc_tf_idf.predict(testData['message'])\n",
    "metrics(testData['label'], preds_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_bow = SpamClassifier(trainData, 'bow')\n",
    "sc_bow.train()\n",
    "preds_bow = sc_bow.predict(testData['message'])\n",
    "metrics(testData['label'], preds_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = process_message('I cant pick the phone right now. Pls send a message')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = process_message('Congratulations ur awarded $500 ')\n",
    "sc_tf_idf.classify(pm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
